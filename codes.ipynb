{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5704201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d5b4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service as EdgeService  # Import EdgeService\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd  # for storing data in a structured way (optional)\n",
    "\n",
    "def extract_station_data_from_page(driver):\n",
    "    \"\"\"Extracts station data from the current page of the table.\"\"\"\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    table = soup.find('table', class_='stn-dir-list-tbl')  # Find the table\n",
    "\n",
    "    if table is None:\n",
    "        print(\"Table not found on this page.\")\n",
    "        return []\n",
    "\n",
    "    station_data = []\n",
    "    rows = table.find_all('tr')  # Get all table rows\n",
    "\n",
    "    # Extract header information\n",
    "    header_row = rows[0]\n",
    "    header_cells = header_row.find_all('th')\n",
    "    headers = [cell.text.strip() for cell in header_cells]\n",
    "\n",
    "    for row in rows[1:]:  # Skip the header row\n",
    "        cells = row.find_all('td')\n",
    "        if not cells:\n",
    "            continue  # Skip empty rows\n",
    "\n",
    "        row_data = {}\n",
    "        for i, cell in enumerate(cells):\n",
    "            if i == 1:  # Handle the station name (which contains a link)\n",
    "                link = cell.find('a')\n",
    "                if link:\n",
    "                    row_data[headers[i]] = link.text.strip()  # Extract link text\n",
    "                else:\n",
    "                    row_data[headers[i]] = cell.text.strip()\n",
    "            else:\n",
    "                row_data[headers[i]] = cell.text.strip()\n",
    "\n",
    "        station_data.append(row_data)\n",
    "\n",
    "    return station_data\n",
    "\n",
    "def extract_all_pages_data(driver, letter):\n",
    "    \"\"\"Extracts station data from all pages for a given letter.\"\"\"\n",
    "    all_data = []\n",
    "    page_num = 1  # Start at page 1\n",
    "\n",
    "    while True:\n",
    "        print(f\"Extracting data from page {page_num} for letter '{letter}'\")\n",
    "        page_data = extract_station_data_from_page(driver)  #Extract data from current page\n",
    "        if not page_data:\n",
    "            print(f\"No data found on page {page_num} for letter '{letter}'. Stopping.\")\n",
    "            break\n",
    "\n",
    "        all_data.extend(page_data)\n",
    "\n",
    "        # Find the \"Next\" button and click it. Use a try-except block in case the button is disabled or not found\n",
    "        try:\n",
    "            next_button = driver.find_element(By.LINK_TEXT, \"Next â†’\")\n",
    "            if 'disabled' in next_button.get_attribute('class'):\n",
    "                print(\"Next button is disabled, no more pages\")\n",
    "                break # Exit if no next page\n",
    "            next_button.click()\n",
    "            driver.implicitly_wait(5) #wait for next page to load\n",
    "            page_num += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Next button not found or could not be clicked. Assuming last page reached. {e}\")\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "# def extract_station_data_for_letter(url, letter):\n",
    "#     \"\"\"Extracts all station data for a given letter, handling multiple pages.\"\"\"\n",
    "\n",
    "#     driver = None  # Initialize driver outside the try block\n",
    "#     try:\n",
    "#         # 1. Set up Selenium Edge WebDriver\n",
    "#         driver = webdriver.Edge()\n",
    "#         driver.get(url)\n",
    "\n",
    "#         # 2. Click on the specified letter\n",
    "#         letter_element = driver.find_element(By.XPATH, f'//a[@class=\"StationName\" and @data-station-name=\"{letter}\"]')\n",
    "#         letter_element.click()\n",
    "#         driver.implicitly_wait(5)\n",
    "\n",
    "#         # 3. Extract data from all pages\n",
    "#         all_data = extract_all_pages_data(driver, letter)  # Modified function call\n",
    "#         return all_data\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n",
    "#         return []\n",
    "\n",
    "#     finally:\n",
    "#         # 5. Close the WebDriver\n",
    "#         if driver:  # Check if the driver was initialized\n",
    "#             driver.quit()\n",
    "#             # Modify the URL to include the letter and page number directly\n",
    "def extract_station_data_for_letter(url, letter):\n",
    "    \"\"\"Extracts all station data for a given letter, handling multiple pages.\"\"\"\n",
    "\n",
    "    driver = None  # Initialize driver outside the try block\n",
    "    try:\n",
    "        # 1. Set up Selenium Edge WebDriver\n",
    "        driver = webdriver.Edge()\n",
    "\n",
    "        # 2. Extract data from all pages\n",
    "        all_data = []\n",
    "        page_num = 1\n",
    "        while True:\n",
    "            # Construct the URL with the letter and page number\n",
    "            page_url = f\"{url}?name={letter}&page={page_num}\"\n",
    "            print(f\"Accessing URL: {page_url}\")\n",
    "            driver.get(page_url)\n",
    "            driver.implicitly_wait(5)\n",
    "\n",
    "            # Extract data from the current page\n",
    "            page_data = extract_station_data_from_page(driver)\n",
    "            if not page_data:\n",
    "                print(f\"No data found on page {page_num} for letter '{letter}'. Stopping.\")\n",
    "                break\n",
    "\n",
    "            all_data.extend(page_data)\n",
    "            page_num += 1\n",
    "\n",
    "        return all_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "    finally:\n",
    "        # 3. Close the WebDriver\n",
    "        if driver:  # Check if the driver was initialized\n",
    "            driver.quit()\n",
    "# Example Usage:\n",
    "url = \"https://www.railyatri.in/stations\"  # Replace with the actual URL of the webpage\n",
    "letters = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"  # All letters to process\n",
    "\n",
    "all_data = {} # Store data for all letters\n",
    "\n",
    "for letter in letters:\n",
    "    \n",
    "    \n",
    "    data = extract_station_data_for_letter(url, letter)\n",
    "\n",
    "    if data:\n",
    "        print(f\"Found {len(data)} stations starting with {letter}\")\n",
    "        all_data[letter] = data # Store data for the letter\n",
    "    else:\n",
    "        print(f\"No data found for letter '{letter}'.\")\n",
    "        all_data[letter] = []\n",
    "\n",
    "# Optional: Convert all data to Pandas DataFrame and save to CSV\n",
    "all_dfs = {}\n",
    "for letter, data in all_data.items():\n",
    "    all_dfs[letter] = pd.DataFrame(data)\n",
    "\n",
    "# Combine all dataframes into a single dataframe:\n",
    "combined_df = pd.concat(all_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(\"all_stations.csv\", index=False)\n",
    "print(\"Data saved to all_stations.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768aba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "PAGE_URL = \"https://www.ixigo.com/hotels\"\n",
    "DESTINATION_CITY = \"Lucknow\"\n",
    "\n",
    "# --- WebDriver Setup ---\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "driver.maximize_window()\n",
    "\n",
    "\n",
    "try:\n",
    "    print(f\"Navigating to {PAGE_URL}...\")\n",
    "    driver.get(PAGE_URL)\n",
    "\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # --- 1. Handle Destination Input ---\n",
    "    print(f\"Locating and updating Destination input...\")\n",
    "\n",
    "    # Retry logic for StaleElementReferenceException\n",
    "    for attempt in range(3):  # Try up to 3 times\n",
    "        try:\n",
    "            destination_input_locator = (By.XPATH, \"//p[text()='Destination']/following-sibling::input\")\n",
    "            destination_input = wait.until(EC.element_to_be_clickable(destination_input_locator))\n",
    "\n",
    "            # *CLICK THE INPUT FIELD FIRST*\n",
    "            destination_input.click()\n",
    "            print(\"Clicked on the Destination input field.\")\n",
    "\n",
    "            destination_input.clear()\n",
    "            destination_input.send_keys(DESTINATION_CITY)\n",
    "            print(f\"Entered '{DESTINATION_CITY}' into Destination input.\")\n",
    "            break  # If successful, exit the loop\n",
    "        except StaleElementReferenceException:\n",
    "            print(f\"StaleElementReferenceException occurred (attempt {attempt + 1}). Retrying...\")\n",
    "            time.sleep(1)  # Wait a bit before retrying\n",
    "    else:  # If the loop completes without a 'break'\n",
    "        print(\"Failed to locate and update Destination input after multiple attempts.\")\n",
    "        raise\n",
    "\n",
    "\n",
    "    try:\n",
    "\n",
    "        # Use the provided HTML to locate the correct element:\n",
    "        mumbai_option_locator = (By.XPATH, f\"//div[@data-testid='{DESTINATION_CITY}' and @role='button']\")\n",
    "        mumbai_option = wait.until(EC.element_to_be_clickable(mumbai_option_locator))\n",
    "        mumbai_option.click()\n",
    "    except TimeoutException:\n",
    "        print(\"Error: Timed out waiting for the 'Mumbai' dropdown item to be clickable.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while selecting 'Mumbai' from dropdown: {e}\")\n",
    "        raise\n",
    "\n",
    "    # --- 3. Handle Search Button ---\n",
    "    print(\"Locating Search button...\")\n",
    "    search_button_locator = (By.CSS_SELECTOR, 'button[data-testid=\"search-hotels\"]')\n",
    "    search_button = wait.until(EC.element_to_be_clickable(search_button_locator))\n",
    "    print(\"Clicking Search button...\")\n",
    "    search_button.click()\n",
    "    print(\"Search initiated successfully!\")\n",
    "\n",
    "    time.sleep(5)\n",
    "    \n",
    "    new_url = driver.current_url\n",
    "    print(f\"New URL: {new_url}\")\n",
    "\n",
    "except TimeoutException:\n",
    "    print(\"Error: Timed out waiting for one or more elements to load or become interactive.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f611f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
